---
title: "2021.01.25 Lecture(1)"
excerpt: "허프 변환을 이용한 차선 인식"
toc: true
toc_sticky: true

categories:
    - 자율주행스쿨강의
tags:
    - Lecture
    - OpenCV
    - ROS
    - RVIZ

last_modified_at: 2021.01.25-13:43:23
---

>이 페이지는 프로그래머스 ((주)그렙)에서 진행하는\
**[K-Digital-Training] 자율주행 데브코스**에서 배운 내용 및 강의자료를 인용하여 작성한 것입니다.

# 허프변환(Hough Transform)
## 허프변환이란?
- 이미지 상에서 직선, 원 등의 특정 모양을 찾는 기법\
![intro](/assets/images/lecture/week09_imgs/intro.png)

## 이론
- 허프변환을 이해하려면 데카르트 좌표계(x, y 좌표계)와 극 좌표계(theta, rho 좌표계)에 대한 약간의 사전 지식이 필요하다.
- 데카르트 좌표계 상에 한 점(x1, y1)은 극좌표계에서는 하나의 곡선(rho = x1cos(theat) + y1sin(theta))으로 표현이 된다.
    > 점(x1, y1) => 곡선 rho = x1cos(theta) + y1sin(theta)
    >> 데카르트 좌표계에서 점(x1, y1)을 지나는 서로 다른 기울기와 거리를 갖는 직선은 무수히 많다.
- 이를 토대로 데카르트 좌표계에서 2개의 점이 존재한다면 극좌표계에서 2개의 곡선으로 표현할 수 있고,
    > 점(x1, y1) => 곡선 rho = x1cos(theta) + y1sin(theta)\
    > 점(x2, y2) => 곡선 rho = x2cos(theta) + y2sin(theta)
- 이 3개의 곡선이 교차하는 점을 찾을 수 있다.
    > 교차점(theta1, rho1)
- 구해진 기울기 theta1과 거리 rho1를 통해, 점(x1, y1), (x2, y2)을 지나는 직선을 그릴 수 있게 된다.\
![hough_theory](/assets/images/lecture/week09_imgs/hough_theory.jpeg)
- 이를 바탕으로, 이미지 상에서 찾은 점을 지나는 직선을 허프변환을 통해 표현할 수 있다.

## OpenCV에서 허프변환 사용
### OpenCV에서 허프변환은 두 가지 방식
1. Standard hough transform
    - `cv2.HoughLines(image, rho, theta, threshold)`
        - image: 8 bit or GrayScale 이미지
        - rho: hough space에서 얼마만큼 rho를 증가시키면서 조사할 것인지 결정하는 인자
        - theta: hough space에서 얼마만큼 theta를 증가시키면서 조사할 것인지 결정하는 인자
        - threshold: hough space에서 threshold 이상의 직선이 겹치는 교점은 하나의 직선을 형성한다고 판단
            > threshold가 높으면, 검출되는 직선은 **적지만**, **확실한 직선**들이 검출됨\
            > threshold가 낮으면, 검출되는 직선은 **많지만**, **불확실한 직선**들도 검출됨\
            ![threshold](/assets/images/lecture/week09_imgs/threshold.png)
    - 검출된 직선의 **(theta, rho)**를 반환함
2. Probabilistic hough transform
    - `cv2.HoughLinesP(image, rho, theta, threshold, minLineLenght, maxLineGap)`
        - minLineLength: 선분의 최소 길이, 이것보다 짧은 선은 버린다.
        - maxLineGap: 간격의 최대 길이, 이것보다 작은 간격은 하나의 선분으로 간주
            > 이 값을 넘어서 떨어져 있는 선분은 각각 다른 선분으로 간주\
            ![maxLineGap](/assets/images/lecture/week09_imgs/maxlinegap.png)
    - 검출된 직선의 **(x, y) 좌표쌍**을 반환함
        > (x1, y1, x2, y2) 형태
3. 두 방식의 차이점
    - **HoughLines**는 **직선**을 검출
    - **HoughLinesP**는 **선분**을 검출\
    ![diff](/assets/images/lecture/week09_imgs/diff.png)
    - 공식문서에 따르면, Probabilistic 방식이 Standard 방식보다 더 효율적이라고 한다.
### 직선 검출 프로세스
1. 이미지를 흑백(GrayScale)로 변환
2. 필터를 사용해 노이즈 제거
    > ex) GaussianBlur
3. Canny 함수를 사용해 외곽선(edge) 검출
4. ROI 관심영역 잘라내기(optional)
5. 직선 검출

## OpenCV 허프변환 예제
### 이미지에서 허프변환
```python
import cv2
import numpy as np
# original image
origin = cv2.imread('test.png')
gray = cv2.cvtColor(origin, cv2.COLOR_BGR2GRAY)
# brightness - 100 
gray = cv2.subtract(gray, 100)
# convert BGR
gray = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
# GaussianBlur filter
blur = cv2.GaussianBlur(gray, (5,5), 0)
# BGR to HSV
hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)
# low-bound
lbound = np.array([0, 0, 100], dtype=np.uint8)
# upper-bound
ubound = np.array([10, 10, 255], dtype=np.uint8)
# binarization
bin_hsv = cv2.inRange(hsv, lbound, ubound)
# cvt_hsv = cv2.cvtColor(bin_hsv, cv2.COLOR_GRAY2BGR)
# Canny edge detection
edge = cv2.Canny(bin_hsv, 10, 20, apertureSize=5, L2gradient=True)

lines = cv2.HoughLinesP(edge, 0.5, np.pi/180, \
                        90, minLineLength = 10, maxLineGap = 100)
if lines is not None:
    for i in range(lines.shape[0]):
        pt1 = (lines[i][0][0], lines[i][0][1])
        pt2 = (lines[i][0][2], lines[i][0][3])
        cv2.line(origin, pt1, pt2, (0, 0, 255), 2, cv2.LINE_AA)

cv2.imshow('Hough_Transform', origin)
cv2.imwrite('hough_test.png', origin)

cv2.waitKey(0)
cv2.destroyAllWindows()
```
|![test](/assets/images/lecture/week09_imgs/test.png)|![hough_test](/assets/images/lecture/week09_imgs/hough_test.png)|
|:---:|:---:|
|Original image|Hough Transform Line Detection|

### 영상에서 허프변환
> 강의에서 제공한 파이썬 코드입니다.
```python
import numpy as np
import cv2, random, math, time

width = 640
height = 480
offset = 420
gap = 40

# draw lines
def draw_lines(img, lines):
    global offset

    for line in lines:
        x1, y1, x2, y2 = line[0]
        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
        img = cv2.line(img, (x1, y1+offset), (x2, y2+offset), color, 2)

    return img

#draw rectangle
def draw_rectangle(img, lpos, rpos, offset=0):
    center = (lpos + rpos) / 2

    cv2.rectangle(img, (lpos - 5, 15 + offset), (lpos + 5, 25 + offset), (0, 255, 0), 2)
    cv2.rectangle(img, (rpos - 5, 15 + offset), (rpos + 5, 25 + offset), (0, 255, 0), 2)
    cv2.rectangle(img, (center - 5, 15 + offset), (center + 5, 25 + offset), (0, 255, 0), 2)
    cv2.rectangle(img, (315, 15 + offset), (325, 25 + offset), (0, 0, 255), 2)

    return img

# left lines, right lines
def divide_left_right(lines):
    global width

    low_slope_threshold = 0
    high_slope_threshold = 10

    # calculate slope & filtering with threshold
    slopes = []
    new_lines = []

    for line in lines:
        x1, y1, x2, y2 = line[0]

        if x2 - x1 == 0:
            slope = 0
        else:
            slope = float(y2 - y1) / float(x2 - x1)

        if abs(slope) > low_slope_threshold and\
           abs(slope) < high_slope_threshold:

            slopes.append(slope)
            new_lines.append(line[0])
    # divide lines left to right
    left_lines = []
    right_lines = []

    for j in range(len(slopes)):
        Line = new_lines[j]
        slope = slopes[j]

        x1, y1, x2, y2 = Line
        if (slope < 0) and (x2 < width/2 - 90):
            left_lines.append([Line.tolist()])
        elif (slope > 0) and (x1 > width/2 + 90):
            right_lines.append([Line.tolist()])

    return left_lines, right_lines

# get average m, b of lines
def get_line_params(lines):
    # sum of x, y, m
    x_sum = 0.0
    y_sum = 0.0
    m_sum = 0.0

    size = len(lines)
    if size == 0:
        return 0, 0
    for line in lines:
        x1, y1, x2, y2 = line[0]

        x_sum += x1 + x2
        y_sum += y1 + y2
        m_sum += float(y2 - y1) / float(x2 - x1)

    x_avg = float(x_sum) / float(size * 2)
    y_avg = float(y_sum) / float(size * 2)

    m = m_sum / size
    b = y_avg - m * x_avg

    return m, b

# get lpos, rpos
def get_line_pos(lines, left=False, right=False):
    global width, height
    global offset, gap

    m, b = get_line_params(lines)

    x1, x2 = 0, 0
    if m == 0 and b == 0:
        if left:
            pos = 0
        if right:
            pos = width
    else:
        y = gap / 2
        pos = (y - b) / m

        b += offset
        x1 = (height - b) / float(m)
        x2 = ((height / 2) - b) / float(m)

    return x1, x2, int(pos)


def process_image(frame):
    global width
    global offset, gap
    # convert BGR to GrayScale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    # Gaussian blur filltering
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    # canny edge
    edge = cv2.Canny(blur, 60, 70)
    # setting roi
    roi = edge[offset:offset+gap, 0:width]
    # Hough Transform
    all_lines = cv2.HoughLinesP(roi, 1, math.pi/180, 30, 30, 10)
    # divide left, right lines
    if all_lines is None:
        return (0, 640), frame

    left_lines, right_lines = divide_left_right(all_lines)
    # get center of lines
    lx1, lx2, lpos = get_line_pos(left_lines, left=True)
    rx1, rx2, rpos = get_line_pos(right_lines, right=True)

    frame = cv2.line(frame, (int(lx1), height), (int(lx2), height//2), (255, 0, 0), 3)
    frame = cv2.line(frame, (int(rx1), height), (int(rx2), height//2), (255, 0, 0), 3)
    # draw lines
    frame = draw_lines(frame, left_lines)
    frame = draw_lines(frame, right_lines)
    frame = cv2.line(frame, (230, 235), (410, 235), (255, 255, 255), 2)

    return (lpos, rpos), frame


def draw_steer(image, steer_angle):
    global width, height, arrow_pic

    arrow_pic = cv2.imread('steer_arrow.png', cv2.IMREAD_COLOR)

    origin_height = arrow_pic.shape[0]
    origin_width = arrow_pic.shape[1]
    steer_wheel_center = origin_height * 0.74
    arrow_height = height // 2
    arrow_width = (arrow_height *  462) // 728

    matrix = cv2.getRotationMatrix2D((origin_width / 2, steer_wheel_center),\
    (steer_angle) * 2.5, 0.7)
    arrow_pic = cv2.warpAffine(arrow_pic, matrix, (origin_width + 60, origin_height))
    arrow_pic = cv2.resize(arrow_pic, dsize=(int(arrow_width), int(arrow_height)),\
    interpolation=cv2.INTER_AREA)

    gray_arrow = cv2.cvtColor(arrow_pic, cv2.COLOR_BGR2GRAY)
    _, mask = cv2.threshold(gray_arrow, 1, 255, cv2.THRESH_BINARY_INV)

    arrow_roi = image[arrow_height:height,\
    (width // 2 - arrow_width // 2):(width // 2 + arrow_width // 2)]
    arrow_roi = cv2.add(arrow_pic, arrow_roi, mask=mask)
    res = cv2.add(arrow_roi, arrow_pic)
    image[(height - arrow_height):height,\
    (width // 2 - arrow_width // 2):(width // 2 + arrow_width // 2)] = res

    cv2.imshow('steer', image)


def start():
    global image, width, height

    cap = cv2.VideoCapture('hough_track.avi')

    while True:
        ret, img = cap.read()
        pos, frame = process_image(img)

        center = (pos[0] + pos[1]) / 2
        angle = 320 - center
        steer_angle = angle * 0.4
        
        draw_steer(frame, steer_angle)
        
        if not ret:
            break
        if cv2.waitKey(30) & 0xFF == 27:
            break
    
    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    start()
```

[![동영상](https://img.youtube.com/vi/awTGwfyXzIk/0.jpg)](https://youtu.be/awTGwfyXzIk)
